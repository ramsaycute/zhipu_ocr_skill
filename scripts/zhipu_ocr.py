#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ™ºè°± GLM-OCR æ–‡æ¡£è§£æè„šæœ¬ (å¹¶å‘å¢å¼ºç‰ˆ)

æ”¯æŒè¾“å…¥:
  - å›¾ç‰‡æ–‡ä»¶ (JPG, PNG)
  - PDF æ–‡ä»¶ (è‡ªåŠ¨è½¬å›¾ç‰‡å¹¶å¹¶å‘å¤„ç†)

ä½¿ç”¨æ–¹æ³•:
  python zhipu_ocr.py <æ–‡ä»¶è·¯å¾„>
"""

import sys
import os
import base64
import json
import mimetypes
import io
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, as_completed

import requests
import fitz  # PyMuPDF
import re

def load_config() -> dict:
    """ä» config.json åŠ è½½é…ç½®"""
    config_path = Path(__file__).parent / "config.json"
    if not config_path.exists():
        raise FileNotFoundError(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
    with open(config_path, 'r', encoding='utf-8') as f:
        return json.load(f)

# åŠ è½½é…ç½®
CONFIG = load_config()
ZHIPU_API_KEY = CONFIG["api_key"]
API_ENDPOINT = CONFIG["api_endpoint"]
MODEL_NAME = CONFIG["model_name"]
MAX_CONCURRENCY = CONFIG.get("max_concurrency", 10)  # ä»é…ç½®è¯»å–ï¼Œé»˜è®¤10

def clean_markdown_text(text: str) -> str:
    """
    æ¸…ç† OCR ç»“æœä¸­çš„ LaTeX ç—•è¿¹å’Œä¸å¿…è¦çš„å…¬å¼ç¬¦å·
    """
    if not text:
        return ""
    
    # 1. ç§»é™¤é¡µé¢å¼€å¤´æˆ–ç»“å°¾å¯èƒ½å‡ºç°çš„æ¨ªçº¿ (---) ç­‰å ä½ç¬¦
    lines = text.split('\n')
    while lines and re.match(r'^\s*[-*_]{3,}\s*$', lines[0]):
        lines.pop(0)
    while lines and re.match(r'^\s*[-*_]{3,}\s*$', lines[-1]):
        lines.pop(-1)
    text = '\n'.join(lines).strip()

    # 2. å¤„ç†å¸¦ mathrm çš„å•ä½: $15\mathrm{g}$ -> 15g
    text = re.sub(r'\$\s*(\d+(?:\.\d+)?)\s*\\mathrm\{([a-zA-Z]+)\}\s*\$', r'\1\2', text)
    # 3. å¤„ç†å•ç‹¬åœ¨å…¬å¼é‡Œçš„å•ä½: 15$\mathrm{g}$ -> 15g
    text = re.sub(r'(\d+(?:\.\d+)?)\s*\$\s*\\mathrm\{([a-zA-Z]+)\}\s*\$', r'\1\2', text)
    # 4. å¤„ç†ç®€å•çš„æ•°å­—å…¬å¼åŒ…è£¹: $15$ -> 15
    text = re.sub(r'\$\s*(\d+(?:\.\d+)?)\s*\$', r'\1', text)
    # 5. å¤„ç†ä¸€äº› OCR å¯èƒ½å‡ºç°çš„ç‰¹æ®Šå­—ç¬¦æ®‹ç•™
    text = text.replace('\\mathrm{g}', 'g')
    
    return text

def is_chinese_char(c: str) -> bool:
    """åˆ¤æ–­å­—ç¬¦æ˜¯å¦ä¸ºä¸­æ–‡"""
    if not c: return False
    return '\u4e00' <= c <= '\u9fff'

def get_image_base64(image_bytes: bytes, mime_type: str = "image/png") -> str:
    """å°†å›¾ç‰‡å­—èŠ‚è½¬æ¢ä¸º Base64 å­—ç¬¦ä¸²"""
    base64_content = base64.b64encode(image_bytes).decode('utf-8')
    return f"data:{mime_type};base64,{base64_content}"

def call_ocr_api_with_data(data_uri: str, label: str = "page") -> dict:
    """è°ƒç”¨æ™ºè°± OCR API å¤„ç† Base64 æ•°æ®"""
    headers = {
        "Authorization": f"Bearer {ZHIPU_API_KEY}",
        "Content-Type": "application/json"
    }
    
    payload = {
        "model": MODEL_NAME,
        "file": data_uri
    }
    
    response = requests.post(
        API_ENDPOINT,
        headers=headers,
        json=payload,
        timeout=120
    )
    
    if response.status_code != 200:
        raise Exception(f"APIè¯·æ±‚å¤±è´¥ [{response.status_code}] ({label}): {response.text}")
    
    return response.json()

def process_single_image(file_path: str):
    """å¤„ç†å•ä¸ªå›¾ç‰‡æ–‡ä»¶"""
    path = Path(file_path)
    mime_type, _ = mimetypes.guess_type(file_path)
    if not mime_type:
        mime_type = "image/png" if path.suffix.lower() == ".png" else "image/jpeg"
    
    with open(file_path, 'rb') as f:
        img_bytes = f.read()
    
    data_uri = get_image_base64(img_bytes, mime_type)
    print(f"ğŸ“¤ æ­£åœ¨å¤„ç†å›¾ç‰‡: {path.name}")
    result = call_ocr_api_with_data(data_uri, path.name)
    md_text = clean_markdown_text(result.get("md_results", ""))
    return md_text, result.get("usage", {})

def check_environment():
    """æ£€æŸ¥è¿è¡Œç¯å¢ƒä¾èµ–"""
    dependencies = ["requests", "fitz"]
    missing = []
    for dep in dependencies:
        try:
            __import__(dep if dep != "fitz" else "fitz")
        except ImportError:
            missing.append("PyMuPDF" if dep == "fitz" else dep)
    
    if missing:
        print(f"âŒ ç¼ºå°‘å¿…è¦çš„ä¾èµ–ç¯å¢ƒ: {', '.join(missing)}")
        print("è¯·å…ˆè¿è¡Œ: pip install requests pymupdf")
        sys.exit(1)
    
    # æ£€æŸ¥å½“å‰å·¥ä½œç›®å½•å†™æƒé™
    if not os.access(os.getcwd(), os.W_OK):
        print(f"âŒ é”™è¯¯: å¯¹å½“å‰å·¥ä½œç›®å½• {os.getcwd()} æ²¡æœ‰å†™æƒé™ï¼Œæ— æ³•åˆ›å»ºç¼“å­˜å’Œç»“æœæ–‡ä»¶ã€‚")
        sys.exit(1)

def process_batch_concurrently(image_tasks: list, cache_dir: Path, smart_merge: bool = True):
    """
    é€šç”¨å¹¶å‘å¤„ç†ä¸€æ‰¹å›¾ç‰‡ä»»åŠ¡
    image_tasks: list of dict { "label": str, "get_data_uri": callable, "index": int }
    smart_merge: PDFä½¿ç”¨True(æµå¼æ‹¼æ¥), æ–‡ä»¶å¤¹å›¾ç‰‡ä½¿ç”¨False(å¸¦æ–‡ä»¶ååˆ†éš”ç¬¦)
    """
    if not cache_dir.exists():
        cache_dir.mkdir(parents=True, exist_ok=True)
        
    total = len(image_tasks)
    # ä½¿ç”¨ç±»å‹æ˜ç¡®çš„åˆå§‹åŒ–ï¼Œæ¶ˆé™¤æŸäº› IDE çš„ç±»å‹è­¦å‘Š
    results: list[str] = [""] * total
    usages = []

    def process_task(task):
        idx = task["index"]
        label = task["label"]
        cache_file = cache_dir / f"page_{idx+1}.json"
        
        # 1. æ£€æŸ¥ç¼“å­˜
        if cache_file.exists():
            try:
                with open(cache_file, 'r', encoding='utf-8') as f:
                    cached_data = json.load(f)
                    print(f"â™»ï¸  [{label}] å·²ä»ç¼“å­˜è¯»å–")
                    return idx, cached_data['md_text'], cached_data.get('usage', {})
            except Exception:
                pass

        # 2. è·å–æ•°æ® 
        data_uri = task["get_data_uri"]()
        print(f"â³ æ­£åœ¨è¯†åˆ« {idx+1}/{total} ({label})...")
        res = call_ocr_api_with_data(data_uri, label)
        md_text = clean_markdown_text(res.get("md_results", ""))
        usage = res.get("usage", {})
        
        # 3. æŒä¹…åŒ–
        with open(cache_file, 'w', encoding='utf-8') as f:
            json.dump({"md_text": md_text, "usage": usage}, f, ensure_ascii=False)
            
        return idx, md_text, usage

    with ThreadPoolExecutor(max_workers=MAX_CONCURRENCY) as executor:
        future_to_task = {executor.submit(process_task, task): task for task in image_tasks}
        for future in as_completed(future_to_task):
            try:
                idx, md_text, usage = future.result()
                results[idx] = md_text
                usages.append(usage)
                print(f"âœ… å¤„ç†å®Œæˆ: {image_tasks[idx]['label']}")
            except Exception as e:
                print(f"âŒ ä»»åŠ¡å¤±è´¥: {e}")

    # åˆå¹¶ç»“æœ
    full_markdown = ""
    for i, page_text in enumerate(results):
        if not page_text: continue
        page_text = page_text.strip()
        label = image_tasks[i]["label"]
        
        if not smart_merge:
            # æ–‡ä»¶å¤¹å›¾ç‰‡æ¨¡å¼ï¼šç»Ÿä¸€ä½¿ç”¨ ### æ–‡ä»¶å ä½œä¸ºæ¯é¡µæ ‡é¢˜
            header = f"### {label}\n\n"
            if not full_markdown:
                full_markdown = header + page_text
            else:
                full_markdown += "\n\n---\n\n" + header + page_text
        else:
            # PDF æ™ºèƒ½åˆå¹¶æ¨¡å¼
            if not full_markdown:
                full_markdown = page_text
            else:
                if page_text.startswith('#'):
                    full_markdown += "\n\n" + page_text
                else:
                    last_char = full_markdown[-1] if full_markdown else ""
                    first_char = page_text[0] if page_text else ""
                    if is_chinese_char(last_char) and is_chinese_char(first_char):
                        full_markdown += page_text
                    else:
                        full_markdown += " " + page_text
    
    total_usage = {
        "prompt_tokens": sum(u.get("prompt_tokens", 0) for u in usages),
        "completion_tokens": sum(u.get("completion_tokens", 0) for u in usages),
        "total_tokens": sum(u.get("total_tokens", 0) for u in usages)
    }
    
    return full_markdown, total_usage

def process_pdf(pdf_path: str):
    path = Path(pdf_path)
    doc = fitz.open(pdf_path)
    # ç¼“å­˜ç›®å½•ç»Ÿä¸€åœ¨å½“å‰æ‰§è¡Œå‘½ä»¤çš„ç›®å½•ä¸‹
    cache_dir = Path.cwd() / f".{path.stem}_cache"
    
    tasks = []
    for i in range(len(doc)):
        def get_uri(p_num=i):
            page = doc.load_page(p_num)
            pix = page.get_pixmap(matrix=fitz.Matrix(2, 2))
            return get_image_base64(pix.tobytes("png"), "image/png")
        
        tasks.append({
            "index": i,
            "label": f"Page {i+1}",
            "get_data_uri": get_uri
        })
    
    return process_batch_concurrently(tasks, cache_dir, smart_merge=True)

def process_directory(dir_path: str):
    path = Path(dir_path)
    valid_suffixes = {'.png', '.jpg', '.jpeg', '.bmp', '.tiff', '.webp'}
    image_files = sorted([
        f for f in path.iterdir() 
        if f.is_file() and f.suffix.lower() in valid_suffixes
    ])
    
    if not image_files:
        raise Exception(f"ç›®å½•ä¸­æœªæ‰¾åˆ°æ”¯æŒçš„å›¾ç‰‡æ–‡ä»¶: {dir_path}")
    
    print(f"ğŸ“¸ æ–‡ä»¶å¤¹æ¨¡å¼: {path.name}, å‘ç° {len(image_files)} å¼ å›¾ç‰‡")
    # ç¼“å­˜ç›®å½•ç»Ÿä¸€åœ¨å½“å‰æ‰§è¡Œå‘½ä»¤çš„ç›®å½•ä¸‹
    cache_dir = Path.cwd() / f".{path.name}_cache"
    
    tasks = []
    for i, img_path in enumerate(image_files):
        def get_uri(p=img_path):
            mime_type, _ = mimetypes.guess_type(str(p))
            if not mime_type: mime_type = "image/png"
            with open(p, 'rb') as f:
                return get_image_base64(f.read(), mime_type)
        
        tasks.append({
            "index": i,
            "label": img_path.name,
            "get_data_uri": get_uri
        })
    
    return process_batch_concurrently(tasks, cache_dir, smart_merge=False)

def main():
    if len(sys.argv) < 2:
        print("ä½¿ç”¨æ–¹æ³•: python zhipu_ocr.py <æ–‡ä»¶è·¯å¾„æˆ–ç›®å½•>")
        sys.exit(1)
    
    # ç¯å¢ƒæ£€æŸ¥
    check_environment()
    
    input_path = sys.argv[1]
    path = Path(input_path)
    
    if not path.exists():
        print(f"âŒ é”™è¯¯: è·¯å¾„ä¸å­˜åœ¨ {input_path}")
        sys.exit(1)
    
    try:
        if path.is_dir():
            print(f"ğŸš€ å¼€å§‹å¹¶å‘å¤„ç†æ–‡ä»¶å¤¹ (å¹¶å‘æ•°: {MAX_CONCURRENCY})...")
            markdown_result, usage = process_directory(input_path)
        elif path.suffix.lower() == ".pdf":
            print(f"ğŸš€ å¼€å§‹å¹¶å‘å¤„ç† PDF (å¹¶å‘æ•°: {MAX_CONCURRENCY})...")
            markdown_result, usage = process_pdf(input_path)
        else:
            print("ğŸ” å¼€å§‹è¯†åˆ«å•å¼ å›¾ç‰‡...")
            markdown_result, usage = process_single_image(input_path)
        
        # è¾“å‡ºä¸ä¿å­˜ï¼šç»Ÿä¸€ä¿å­˜åœ¨å½“å‰å·¥ä½œç›®å½•
        output_path = Path.cwd() / (path.stem + "_ocr_result.md")
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(markdown_result)
        
        # è¾“å‡ºä¸ä¿å­˜
        print("\n" + "="*60)
        print("ğŸ“ OCR å¤„ç†å®Œæˆ")
        print("="*60)
        
        if usage:
            print(f"\nğŸ“Š æ€» Token ä½¿ç”¨ç»Ÿè®¡:")
            print(f"   - è¾“å…¥: {usage.get('prompt_tokens')}")
            print(f"   - è¾“å‡º: {usage.get('completion_tokens')}")
            print(f"   - æ€»è®¡: {usage.get('total_tokens')}")
            
        print(f"\nâœ… ç»“æœå·²ä¿å­˜è‡³: {output_path}")
        
    except Exception as e:
        print(f"âŒ å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)



if __name__ == "__main__":
    main()
